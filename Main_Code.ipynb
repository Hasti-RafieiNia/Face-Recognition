{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "\n",
    "# Disable all logs except for errors\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
    "\n",
    "# Paths\n",
    "video_path = 'D:/project/Data/1.mp4'\n",
    "target1_path = 'D:/project/Data/Target01.jpg'\n",
    "target2_path = 'D:/project/Data/Target02.png'\n",
    "weights_path = 'D:/project/YOLOv8/best.pt'  # YOLOv8 model in .pt format\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(weights_path)\n",
    "\n",
    "# Load target images\n",
    "target1_img = face_recognition.load_image_file(target1_path)\n",
    "target2_img = face_recognition.load_image_file(target2_path)\n",
    "\n",
    "# Extract face encodings\n",
    "target1_encoding = face_recognition.face_encodings(target1_img)[0]\n",
    "target2_encoding = face_recognition.face_encodings(target2_img)[0]\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to 600x800\n",
    "    frame = cv2.resize(frame, (600, 800))\n",
    "\n",
    "    # Use YOLOv8 model for detection without printing speed outputs\n",
    "    results = model(frame)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    # Process detections\n",
    "    for detection in results:\n",
    "        for box in detection.boxes:\n",
    "            if box.conf > 0.3 and box.cls == 0:  # Assuming class \"person\" in YOLOv8 is class 0\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                boxes.append([x1, y1, w, h])\n",
    "                confidences.append(float(box.conf))\n",
    "\n",
    "    # Process detections and recognize faces\n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        face_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Convert face_frame from BGR to RGB\n",
    "        face_frame_rgb = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect face locations in the frame\n",
    "        face_locations = face_recognition.face_locations(face_frame_rgb)\n",
    "\n",
    "        # If a face is detected, extract the face encoding\n",
    "        if len(face_locations) > 0:\n",
    "            face_encodings = face_recognition.face_encodings(face_frame_rgb, face_locations)\n",
    "\n",
    "            if len(face_encodings) > 0:\n",
    "                match = None\n",
    "                face_encoding = face_encodings[0]\n",
    "\n",
    "                if face_recognition.compare_faces([target1_encoding], face_encoding)[0]:\n",
    "                    color = (0, 0, 255)  # Red\n",
    "                    match = \"Target 1\"\n",
    "                elif face_recognition.compare_faces([target2_encoding], face_encoding)[0]:\n",
    "                    color = (0, 0, 255)  # Red\n",
    "                    match = \"Target 2\"\n",
    "                else:\n",
    "                    color = (0, 255, 255)  # Yellow\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "                # Write the target name\n",
    "                if match:\n",
    "                    cv2.putText(frame, match, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Display the frame with the new size 600x800\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import face_recognition\n",
    "from ultralytics import YOLO\n",
    "import logging\n",
    "\n",
    "# Disable all logs except for errors\n",
    "logging.getLogger('ultralytics').setLevel(logging.ERROR)\n",
    "\n",
    "# Paths\n",
    "video_path = 'D:/project/Data/1.mp4'\n",
    "target1_path = 'D:/project/Data/Target01.jpg'\n",
    "target2_path = 'D:/project/Data/Target02.png'\n",
    "weights_path = 'D:/project/YOLO5/best.pt'  # YOLOv5 model in .pt format\n",
    "\n",
    "# Load YOLOv8 model\n",
    "model = YOLO(path)\n",
    "\n",
    "# Load target images\n",
    "target1_img = face_recognition.load_image_file(target1_path)\n",
    "target2_img = face_recognition.load_image_file(target2_path)\n",
    "\n",
    "# Extract face encodings\n",
    "target1_encoding = face_recognition.face_encodings(target1_img)[0]\n",
    "target2_encoding = face_recognition.face_encodings(target2_img)[0]\n",
    "\n",
    "# Start video capture\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Resize frame to 600x800\n",
    "    frame = cv2.resize(frame, (600, 800))\n",
    "\n",
    "    # Use YOLOv8 model for detection without printing speed outputs\n",
    "    results = model(frame)\n",
    "\n",
    "    boxes = []\n",
    "    confidences = []\n",
    "\n",
    "    # Process detections\n",
    "    for detection in results:\n",
    "        for box in detection.boxes:\n",
    "            if box.conf > 0.5 and box.cls == 0:  # Assuming class \"person\" in YOLOv8 is class 0\n",
    "                x1, y1, x2, y2 = map(int, box.xyxy[0])\n",
    "                w = x2 - x1\n",
    "                h = y2 - y1\n",
    "                boxes.append([x1, y1, w, h])\n",
    "                confidences.append(float(box.conf))\n",
    "\n",
    "    # Process detections and recognize faces\n",
    "    for i, (x, y, w, h) in enumerate(boxes):\n",
    "        face_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Convert face_frame from BGR to RGB\n",
    "        face_frame_rgb = cv2.cvtColor(face_frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Detect face locations in the frame\n",
    "        face_locations = face_recognition.face_locations(face_frame_rgb)\n",
    "\n",
    "        # If a face is detected, extract the face encoding\n",
    "        if len(face_locations) > 0:\n",
    "            face_encodings = face_recognition.face_encodings(face_frame_rgb, face_locations)\n",
    "\n",
    "            if len(face_encodings) > 0:\n",
    "                match = None\n",
    "                face_encoding = face_encodings[0]\n",
    "\n",
    "                if face_recognition.compare_faces([target1_encoding], face_encoding)[0]:\n",
    "                    color = (0, 0, 255)  # Red\n",
    "                    match = \"Target 1\"\n",
    "                elif face_recognition.compare_faces([target2_encoding], face_encoding)[0]:\n",
    "                    color = (0, 0, 255)  # Red\n",
    "                    match = \"Target 2\"\n",
    "                else:\n",
    "                    color = (0, 255, 255)  # Yellow\n",
    "\n",
    "                # Draw bounding box\n",
    "                cv2.rectangle(frame, (x, y), (x+w, y+h), color, 2)\n",
    "\n",
    "                # Write the target name\n",
    "                if match:\n",
    "                    cv2.putText(frame, match, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)\n",
    "\n",
    "    # Display the frame with the new size 600x800\n",
    "    cv2.imshow(\"Video\", frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
